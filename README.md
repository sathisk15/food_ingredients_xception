# Image â†’ Ingredients Multi-Label Classification (Xception from Scratch)

This project implements an **image-to-ingredients multi-label classification system** using a **from-scratch Xception architecture** in **pure PyTorch**.

The model predicts a set of ingredients given a food image, trained on the Kaggle  
**Food Ingredients and Recipe Dataset with Images**.

---

## ğŸ”’ Constraints (Strictly Followed)

- **Xception implemented completely from scratch**
  - No pretrained weights
  - No `torchvision.models`
  - No `timm`, Keras, HuggingFace, etc.
- **Pure PyTorch + standard Python libraries**
- **Multi-label classification**
  - Sigmoid outputs
  - `BCEWithLogitsLoss`
- **Cross-platform**
  - macOS (Apple Silicon, MPS backend)
  - Windows (CUDA or CPU) without code changes

---

## ğŸ“ Project Structure

```
food_ingredients_xception/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ Food Images/
â”‚   â”‚   â””â”€â”€ Food Ingredients and Recipe Dataset with Image Name Mapping.csv
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ ingredient_vocab.json
â”‚       â”œâ”€â”€ ingredient_vocab_pruned.json
â”‚       â”œâ”€â”€ labels.npy
â”‚       â””â”€â”€ labels_pruned.npy
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ datasets/
â”‚   â”‚   â””â”€â”€ food_dataset.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ layers.py
â”‚   â”‚   â””â”€â”€ xception.py
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â””â”€â”€ evaluate.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ device.py
â”‚   â””â”€â”€ inference.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ prepare_dataset.py
â”‚   â”œâ”€â”€ encode_labels.py
â”‚   â””â”€â”€ prune_labels.py
â”‚
â”œâ”€â”€ run_train.py
â”œâ”€â”€ checkpoints/
â”œâ”€â”€ checkpoints_pruned/
â””â”€â”€ README.md
```

---

## ğŸ§  Model Architecture

- **Xception (Chollet-style)**
  - Depthwise separable convolutions
  - Residual connections
  - Entry / Middle / Exit flows
- **Adaptive Average Pooling**
- **Fully connected classifier**
- **No sigmoid inside the model**
  - Sigmoid applied only for evaluation/inference

---

## ğŸ·ï¸ Label Strategy

### Initial Labeling

- Ingredients parsed directly from recipe text
- Minimal cleaning
- Top **1000 most frequent labels**

### Pruning

- Labels appearing in `< 50` samples removed
- Final label space: **~400 ingredients**
- Statistical pruning only (no NLP tricks)

---

## ğŸš€ Training

### Device Handling

Automatically selects:

1. MPS (Apple Silicon)
2. CUDA
3. CPU

### Loss & Optimizer

- `BCEWithLogitsLoss`
- `AdamW`
- Gradient clipping (`1.0`)
- Batch size: `16` (MPS-safe)

### Run Training

```bash
python run_train.py
```

---

## ğŸ“Š Evaluation

Metrics:

- Micro Precision / Recall / F1
- Macro F1

---

## ğŸ” Inference (Single Image)

```bash
python - << 'EOF'
from src.inference import predict_ingredients

preds = predict_ingredients(
    image_path="data/raw/Food Images/example.jpg",
    checkpoint_path="checkpoints_pruned/xception_epoch_10.pt",
    vocab_path="data/processed/ingredient_vocab_pruned.json",
    top_k=10,
)

for ing, score in preds:
    print(ing, score)
EOF
```

---

## âš ï¸ Known Limitations

- Some non-visual labels may still exist if they are frequent
- Recipe text contains noise (instructions, quantities)
- No validation split
- No data augmentation

---

## ğŸ“Œ Future Improvements

- Manual blacklist of non-visual labels
- Validation split + threshold calibration
- Class imbalance weighting
- Data augmentation

---

## âœï¸ Author

**Sathiskumar**  
MSc Applied Computer Science
